{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_download_preprocess.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "T5UNFdjGYJbb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "## Pyplot from Matplotlib for vizualising the test results in plots\n",
        "import matplotlib.pyplot as plt\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "import skimage.color as skcolor\n",
        "from PIL import Image\n",
        "import math\n",
        "import h5py\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PzRVTpYaYJbf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function padding the int to the given size\n",
        "## length:           int, the length of\n",
        "## return value:     String, %0(length)d\n",
        "def formatint(length):\n",
        "  return str('%0' + str('%d'% length)+'d')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1D55wyQuYJbj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Function for making folder if it does not exist in the given path.\n",
        "#@ Used packages:\n",
        "  #@ os\n",
        "## path:     String, filepath needed to be verified\n",
        "def MakePath(path):\n",
        "  #Creating folder if it does not exist.\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q47pGVNNYJbm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Function for printing text and the time\n",
        "#@ Used packages:\n",
        "  #@ datetime\n",
        "## string:        String, the printed text\n",
        "## return value:  datetime, the printings time\n",
        "def PrintTime(string):\n",
        "    time = datetime.datetime.now()\n",
        "    print(string+ str(time));\n",
        "    return time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jo9zAXPhYJbp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Class for Collecting Data\n",
        "#@ Used packages:\n",
        "  #@ requests\n",
        "  #@ zipfile\n",
        "  #@ os\n",
        "class DataCollect:\n",
        "    # Class Variables\n",
        "    ## url:                   String, url of the zipped dataset \n",
        "    ## dataset_zip_path:      String, filepath of the downloaded zip\n",
        "    ## raw_dataset_path:      String, intended folder path of raw dataset\n",
        "    url              = \"Not initialized.\"\n",
        "    dataset_zip_path = \"Not initialized.\"\n",
        "    raw_dataset_path = \"Not initialized.\"\n",
        "    # Class Constructor\n",
        "    ## url:           String, url of the zipped dataset \n",
        "    def __init__(self, url):\n",
        "        ## Initializing the url class variable\n",
        "        self.url = url\n",
        "\n",
        "    # Function for downloading the dataset.\n",
        "    ## target_path:   String, intended filepath of the downloaded dataset\n",
        "    def download_dataset(self, target_path):\n",
        "        ## Saving the dataset zip path to class variable\n",
        "        self.dataset_zip_path = target_path\n",
        "\n",
        "        PrintTime('Start zip file download from: ' + self.url +'\\n\\t')\n",
        "\n",
        "        ## Downloading the file in chunks to avoid memory overrun.\n",
        "        r = requests.get(self.url, stream = True)\n",
        "        with open(target_path, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=1024):\n",
        "                ## Filtering out keep-alive new chunks.\n",
        "                if chunk: \n",
        "                    f.write(chunk)\n",
        "\n",
        "        PrintTime('Zip file download.\\n\\t')\n",
        "    # Function for extracting zipped dataset.\n",
        "    ## raw_dataset_path:      String, intended folder path of raw dataset\n",
        "    ## return value:          String, final folder path of raw dataset\n",
        "    def extract_dataset(self, raw_dataset_path):\n",
        "        ## Creating directory for the raw dataset, if it does not exist.\n",
        "        MakePath(raw_dataset_path)\n",
        "\n",
        "        PrintTime('Start images extraction.\\n\\t')\n",
        "\n",
        "        ## Extracting dataset to the intended folder path.\n",
        "        zip_ref = zipfile.ZipFile(self.dataset_zip_path, 'r')\n",
        "        zip_ref.extractall(raw_dataset_path)\n",
        "        zip_ref.close()\n",
        "\n",
        "        ## Determining and returning final path of the raw dataset.\n",
        "        dirlist = os.listdir(raw_dataset_path)\n",
        "\n",
        "        ## Saving the raw dataset path to class variable\n",
        "        self.raw_dataset_path = raw_dataset_path + dirlist[0] + '/'\n",
        "\n",
        "        PrintTime('Images are extracted.\\n\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Khg0ekZCYJbs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Class for Collecting Data\n",
        "#@ Used packages:\n",
        "  #@ from PIL Image\n",
        "  #@ numpy as np\n",
        "  #@ os\n",
        "  #@ h5py\n",
        "  #@ skimage.color as skcolor\n",
        "  #@ random\n",
        "  #@ datetime\n",
        "#@ Used functions:\n",
        "  #@ MakePath\n",
        "  #@ PrintTime\n",
        "class DataPreProcess:\n",
        "    # Class Constructor\n",
        "    ## initial_path:           String, the filepath with the raw images\n",
        "    ## target_path:            String, filepath for the transformed images\n",
        "    ## image_size:             tuple with 2 integer element, (width, height)\n",
        "    def __init__(self, initial_path, target_path, image_size, train_split = 0.9, validation_split = 0.05, test_split = 0.05):\n",
        "        self.raw_dataset_path         = initial_path\n",
        "        self.transformed_dataset_path = target_path\n",
        "        self.image_size               = image_size\n",
        "        self.train_sp                 = train_split \n",
        "        self.valid_sp                 = validation_split\n",
        "        self.test_sp                  = test_split\n",
        "\n",
        "    # Function for transforming the images of the dataset to 1:1 ratio, and target size.\n",
        "    def dataset_transform(self):\n",
        "        ## Creating directory for the transformed dataset, if it does not exist.\n",
        "        MakePath(self.transformed_dataset_path)\n",
        "\n",
        "        PrintTime('Start dataset transforming.\\n\\t')\n",
        "\n",
        "        ## Iterating over the raw images.\n",
        "        for filename in os.listdir(self.raw_dataset_path):\n",
        "            im = Image.open(self.raw_dataset_path + filename)\n",
        "            ## Filtering out the grayscale images, and images with improper dimensions.\n",
        "            if((self.is_gray_scale(im) == False) and (self.has_proper_dim(im) == True)):\n",
        "                ## Making the images to 1:1 ratio, and resizing them to the target size.\n",
        "                im = self.crop_resize_Image(im)\n",
        "                ## Saving the images to the target directory.\n",
        "                im.save(self.transformed_dataset_path + filename, quality=90)\n",
        "        PrintTime('Dataset transformed.\\n\\t')\n",
        "    # Function for grayscale check of an image. Returns True if grayscale, False if not.\n",
        "    ## im:            PIL.Image object, input image\n",
        "    ## return value:  boolean, True if grayscale, False if not grayscale\n",
        "    def is_gray_scale(self, im):\n",
        "        w,h = im.size\n",
        "        ## Generating 10 random pixel coordinate.\n",
        "        rand_pixel_array = np.zeros((10,2))\n",
        "        for i in range(10):\n",
        "            rand_pixel_array[i,:] = [random.randint(0,w-1), random.randint(0,h-1)]\n",
        "        ## If all of the 10 pixels have the same values on each channels, the image is regarded grayscale.\n",
        "        for i in range(10):\n",
        "            r,g,b = im.getpixel((rand_pixel_array[i,0], rand_pixel_array[i,1]))\n",
        "            if r != g != b: return False\n",
        "        return True\n",
        "    # Function for dimension check of an image. Returns True if if image has the proper dimensions (3D, 3 channels), False if not.\n",
        "    ## im:            PIL.Image object, input image\n",
        "    ## return value:  boolean, True if image has the proper dimensions (3D, 3 channels), False if not\n",
        "    def has_proper_dim(self, im):\n",
        "        ## Get the image data to numpy array.\n",
        "        im_array = np.array(im)\n",
        "        shape = im_array.shape\n",
        "        ## The image shall have 3 dimensions, and 3 channels.\n",
        "        if((len(shape) != 3) or (shape[2] != 3)):\n",
        "            return False\n",
        "        else:\n",
        "            return True    \n",
        "    # Function for making the images to 1:1 ratio, and resizing them to the targetted image size.\n",
        "    ## im:           PIL.Image object, input image\n",
        "    ## return value: PIL.Image object, transformed image\n",
        "    def crop_resize_Image(self, im):\n",
        "        ## Taking out the image data (width,height).\n",
        "        width,height = im.size\n",
        "        ## Deciding if the image is landscape or portrait.\n",
        "        if(width > height):\n",
        "            ## Landscape\n",
        "            top     = 0\n",
        "            left    = int((width - height)/2)\n",
        "            bottom  = height\n",
        "            right    = width - int((width - height)/2)\n",
        "        else:\n",
        "            ## Portrait.\n",
        "            top     = int((height - width)/2)\n",
        "            left    = 0\n",
        "            bottom  = height-int((height - width)/2)\n",
        "            right    = width\n",
        "        ## Cropping the image to conform 1:1 ratio, the resizing to target size.\n",
        "        return im.crop((left,top,right,bottom)).resize(self.image_size, resample=PIL.Image.LANCZOS)\n",
        "    #Function for converting RGB images from path to LAB images.\n",
        "    ## path:          String, filepath of the images\n",
        "    ## return value:  Float array 128x128x3, The array of the images in LAB colorization\n",
        "    def path2labimage(self, path):\n",
        "        ## Opening the image from path and converting it to float array\n",
        "        raw_image_array = np.array(Image.open(path)).astype('float32')\n",
        "        ## Converting RGB image to LAB\n",
        "        image_array = (skcolor.rgb2lab(raw_image_array/255.0)).astype('int8')\n",
        "        ## Returning the float array with the LAB image values\n",
        "        \n",
        "    # Function converting the rgb images to LAB and saving it to a hd5f file\n",
        "    ## target_path:  String, the file path\n",
        "    ## in_one_file:  Boolean, default value false, if true then the dataset is saved in one file\n",
        "    def dataset_rgb2lab_hdf5(self, target_path, in_one_file = True):\n",
        "        PrintTime('Start dataset transforming.\\n\\t')\n",
        "        ## Creating directory for the transformed dataset, if it does not exist.\n",
        "        MakePath(target_path)\n",
        "        if not(in_one_file):\n",
        "            MakePath(target_path + 'train/')\n",
        "            MakePath(target_path + 'valid/')\n",
        "            MakePath(target_path + 'test/')\n",
        "            \n",
        "        ## Initializing local variables\n",
        "        files = os.listdir(self.transformed_dataset_path)\n",
        "        t1=datetime.datetime.now()\n",
        "        iterator = 0\n",
        "        \n",
        "        ## Initializing local variables used when saving data in one file\n",
        "        if in_one_file:\n",
        "            train_iterator = 0\n",
        "            val_iterator = 0\n",
        "            test_iterator = 0\n",
        "            h5 = h5py.File(target_path + 'dataset.h5df','w')\n",
        "            h5_train = h5.create_group('train')\n",
        "            h5_test = h5.create_group('test')\n",
        "            h5_val = h5.create_group('val')\n",
        "            \n",
        "        ## Iterating over the raw images.\n",
        "        for fileName in (files):\n",
        "            \n",
        "            ## Loading screen, for estimating the time needed \n",
        "            t2 = datetime.datetime.now()\n",
        "            if(t2.minute != t1.minute):\n",
        "                print(str(iterator) + '/' + str(len(files)) + '\\t' + str(t2))\n",
        "                t1=t2\n",
        "            ## Converting path to LAB image\n",
        "            image_array = self.path2labimage(self.transformed_dataset_path + fileName)\n",
        "            \n",
        "            ## Saving the dataset to files\n",
        "            if not(in_one_file):\n",
        "                ## Seperate train, valid, test data\n",
        "                if iterator < len(files)*self.train_sp:\n",
        "                    ## Opening file for writing\n",
        "                    h5  = h5py.File(target_path + 'train/' + fileName[:-3] + 'h5df','w')\n",
        "                    ## Saving lab image array \n",
        "                    h5.create_dataset('images_dataset', data = image_array, dtype = 'int8')\n",
        "                    ## Saving to a h5df files\n",
        "                    h5.close()\n",
        "                elif iterator < len(files)*(self.train_sp + self.valid_sp):\n",
        "                    ## Opening file for writing \n",
        "                    h5  = h5py.File(target_path + 'valid/' + fileName[:-3] + 'h5df','w')\n",
        "                    ## Saving lab image array \n",
        "                    h5.create_dataset('images_dataset', data = image_array, dtype = 'int8')\n",
        "                    ## Saving to a h5df files\n",
        "                    h5.close()\n",
        "                else:\n",
        "                    ## Opening file for writing \n",
        "                    h5  = h5py.File(target_path + 'test/' + fileName[:-3] + 'h5df','w')\n",
        "                    ## Saving lab image array \n",
        "                    h5.create_dataset('images_dataset', data = image_array, dtype = 'int8')\n",
        "                    ## Saving to a h5df files\n",
        "                    h5.close()\n",
        "                iterator += 1\n",
        "            \n",
        "            ## Saving the dataset to file\n",
        "            if in_one_file:\n",
        "                ## Seperate train, valid, test data\n",
        "                if iterator < len(files)*self.train_sp:\n",
        "                    ## Saving lab image array \n",
        "                    h5_train.create_dataset('image'+str(train_iterator),data = image_array, dtype = 'int8')\n",
        "                    train_iterator +=1\n",
        "                elif iterator < len(files)*(self.train_sp + self.valid_sp):\n",
        "                    ## Saving lab image array \n",
        "                    h5_val.create_dataset('image'+str(val_iterator),data = image_array, dtype = 'int8')\n",
        "                    val_iterator +=1\n",
        "                else:\n",
        "                    ## Saving lab image array \n",
        "                    h5_test.create_dataset('image'+str(test_iterator),data = image_array, dtype = 'int8')\n",
        "                    test_iterator +=1\n",
        "                iterator += 1\n",
        "        ## Closing the file and saving after all data is written\n",
        "        if in_one_file:       \n",
        "            h5.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KKXtYiSbYJbv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_size = (128,128)\n",
        "# Specifying zipped dataset url.\n",
        "dataset_url = 'https://datasets.figure-eight.com/figure_eight_datasets/open-images/test_challenge.zip'\n",
        "# Specifying intended filepath for the dataset to be downloaded.\n",
        "dataset_zipped_path = os.getcwd() + '/zipped_dataset.zip'\n",
        "# Specifying intended folder path of raw dataset.\n",
        "raw_dataset_path = os.getcwd() + '/raw_dataset/'\n",
        "# Specifying intended folder path of transformed dataset.\n",
        "transformed_dataset_path = os.getcwd() + '/transformed_dataset/'\n",
        "hdf5_images_path = os.getcwd()+'/images_hdf5/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ArkgEUrPYJby",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datac = DataCollect(dataset_url)\n",
        "#Downloading the Dataset zip\n",
        "datac.download_dataset(dataset_zipped_path)\n",
        "#Extracting the dataset from the previously downloaded zip file\n",
        "datac.extract_dataset(raw_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YcMZ9DFeYJb1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datap = DataPreProcess(datac.raw_dataset_path, raw_dataset_path+'/transformed_dataset/', image_size)\n",
        "#Transforming the dataset\n",
        "datap.dataset_transform()\n",
        "#Preparing the dataset for training\n",
        "datap.dataset_rgb2lab_hdf5(hdf5_images_path, True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}