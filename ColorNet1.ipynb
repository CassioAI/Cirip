{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9qBI03FrcgL"
   },
   "source": [
    "#  A short introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oCPtUo00rcgQ"
   },
   "source": [
    "We are working on a project to color grayscale pictures.\n",
    "The first few aspect of our project that we would like to introduce in this short introduction, are the decisions we took in our current approach to the problem.\n",
    "\n",
    "The Dataset:\n",
    "At first we were planning on using the ImageNet Database, but soon it became evident, that due to some technical difficulties on the site we weren't going to get access, so we decided on our current Database (Open Images V4 Dataset) which granted us the original images in a zip file. The images are not restricted to a single subject, the dataset incorporates images with various themes. We decided to start with 100000 images.\n",
    "(https://www.figure-eight.com/dataset/open-images-annotated-with-bounding-boxes/)\n",
    "\n",
    "The Images:\n",
    "Although the Images in the Database were mostly satisfactory for our goals, there were some modifications we had to make on them. Since the images were too big for us to handle and they did not have the same measurements we decided to crop them into a square shape and scale them down to resolution of 128X128. Also some of the pictures were not appropriate for our task such as grayscale pictures, so we decided, to sort them out.\n",
    "\n",
    "The LAB color scale:\n",
    "We decided to convert the images from RGB color space to LAB, which hopefully will make the teaching easier, as the L channel of LAB colorspace is the greyscale representation of the image, so the machine will only have to predict two channels instead of 3.\n",
    "\n",
    "Normalization:\n",
    "We decided to normalize the whole dataset as a preprocessing step, load every image to a numpy array, normalize it, then save it to a csv file, resulting in a normalized dataset of csv files. This way we can avoid the normalization of the images in every training step.\n",
    "\n",
    "The Small Parts:\n",
    "Even with a 128X128 scaling the whole dataset is too big to be loaded to the operating memory as a numpy array, so we decided to divide it into smaller parts, and teach the neural network on each smaller part individually.\n",
    "\n",
    "This version contains only the result of a single training step with 1000 images and 10 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m79XKvNKrcgY"
   },
   "source": [
    "# The preparation and preprocessing of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XesJ2Jrcrcgi"
   },
   "outputs": [],
   "source": [
    "# Importing the used packages\n",
    "\n",
    "# Numpy for arrays\n",
    "import numpy as np\n",
    "# requests for downloading the dataset\n",
    "import requests\n",
    "# PIL.Image for image processing\n",
    "from PIL import Image\n",
    "# keras.preprocessing.image for image processing\n",
    "import keras.preprocessing.image as k_image\n",
    "# os for file management\n",
    "import os\n",
    "# skimage.color for transforming the color model of images\n",
    "import skimage.color as skcolor\n",
    "# zipfile for extracting downloaded dataset \n",
    "import zipfile\n",
    "# random for random number generation in grayscale check\n",
    "import random\n",
    "# datetime for making timestamps\n",
    "import datetime\n",
    "# pyplot from Matplotlib for vizualising the test results in plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Math for Sqrt\n",
    "import math\n",
    "# Genfromtxt to convert our csv file to array\n",
    "from numpy import genfromtxt\n",
    "# Keras.* for building my fully connected dense neural network \n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation,Flatten\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import SGD\n",
    "# Mean_squared_error from sklearn.metrics for calculating mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# keras.callbacks.* for Earlystopping (modelcheckpoint is needed to load back the weights)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CoQZxGOl9S9"
   },
   "outputs": [],
   "source": [
    "#Function for converting RGB images from path to LAB images.\n",
    "# path:          String, filepath of the images\n",
    "# return value:  Float array 128x128x3, The array of the images in LAB colorization\n",
    "def path2labimage(path):\n",
    "  #Opening the image from path and converting it to float array\n",
    "  raw_image_array = np.array(Image.open(path)).astype('float32')\n",
    "  #Converting RGB image to LAB\n",
    "  image_array = skcolor.rgb2lab(raw_image_array/255)\n",
    "  #Returning the float array with the LAB image values\n",
    "  return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRwOLPyJhDWZ"
   },
   "outputs": [],
   "source": [
    "#Function for normalizing the images and saving it to csv files.\n",
    "# initial_path:          String, filepath of the images\n",
    "# target_path:           String, intended folder path of csv files\n",
    "# array_average:         Int, the average value of the train dataset\n",
    "# array_std:             Int, the standard deviation value of the train dataset\n",
    "def dataset_normalized_csv(initial_path,target_path,array_average,array_std):\n",
    "    # Creating directory for the transformed dataset, if it does not exist.\n",
    "    if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "      \n",
    "    # Variables for printing the number of already normalized images.\n",
    "    i=0\n",
    "    t1=datetime.datetime.now()\n",
    "    # Iterating over the raw images.\n",
    "    for filename in os.listdir(initial_path):\n",
    "        \n",
    "        # Print the number of normalized images in every minute.\n",
    "        t2 = datetime.datetime.now()\n",
    "        if(t2.minute != t1.minute):\n",
    "            print(str(i)+'/'+str(len(os.listdir(initial_path))))\n",
    "            t1=t2\n",
    "        i+=1\n",
    "        \n",
    "        #Converting path to LAB image\n",
    "        image_array = path2labimage(initial_path + filename)\n",
    "        #Normalizing the grayimage\n",
    "        image_array[:,:,0] = (image_array[:,:,0]-array_average)/array_std\n",
    "        #Min max scaling the color dimensions\n",
    "        image_array[:,:,1::] = image_array[:,:,1::]+128\n",
    "        image_array[:,:,1::] = image_array[:,:,1::]/255\n",
    "        #Saving to a csv files\n",
    "        np.savetxt((target_path + filename[:-3] + 'csv'), image_array.reshape((-1,3)), delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEww1VNChD8I"
   },
   "outputs": [],
   "source": [
    "#Function for calculating the average and standard ddeviation of the dataset.\n",
    "# initial_path:           String, path of the folder of the transformed dataset\n",
    "# image size              int, size of the images\n",
    "# valid_split             float32, split of the validation data\n",
    "# test_split              float32, split of the test data\n",
    "# return value            standard deviation, average\n",
    "def dataset_std(initial_path, image_size, valid_split, test_split):\n",
    "    NA = image_size*image_size;\n",
    "    NB = 0;\n",
    "    SA = 0;\n",
    "    SB = 'a';\n",
    "    a_ave = 0;\n",
    "    b_ave = 0;\n",
    "    \n",
    "    for filename in os.listdir(initial_path):\n",
    "\n",
    "        image_array = path2labimage(initial_path + filename)\n",
    "        SA = np.std(image_array[:,:,0])\n",
    "        a_ave = np.average(image_array[:,:,0])\n",
    "        if(SB=='a'):\n",
    "            SB = SA\n",
    "            NB += NA\n",
    "            b_ave = a_ave;\n",
    "        else:\n",
    "            SB =math.sqrt(((NA-1)*(SA**2)+(NB-1)*(SB**2)+NA*NB/(NA+NB)*math.pow(a_ave-b_ave,2))/(NA+NB-1))\n",
    "            b_ave = (b_ave*NB+a_ave*NA)/(NB+NA)\n",
    "            NB += NA\n",
    "\n",
    "    return  SB,b_ave   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2pMnKBhrcgv"
   },
   "outputs": [],
   "source": [
    "# Function for downloading the dataset.\n",
    "# url:           String, url of the zipped dataset\n",
    "# target_path:   String, intended filepath of the downloaded dataset\n",
    "def download_dataset(url, target_path):\n",
    "    # Downloading the file in chunks to avoid memory overrun.\n",
    "    r = requests.get(url, stream = True)\n",
    "    with open(target_path, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            # Filtering out keep-alive new chunks.\n",
    "            if chunk: \n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cX7THU6Crcg9"
   },
   "outputs": [],
   "source": [
    "#Function for extracting zipped dataset.\n",
    "# dataset_zipped_path:   String, filepath of the zipped dataset\n",
    "# raw_dataset_path:      String, intended folder path of raw dataset\n",
    "# return value:          String, final folder path of raw dataset\n",
    "def extract_dataset(dataset_zipped_path, raw_dataset_path):\n",
    "    # Creating directory for the raw dataset, if it does not exist.\n",
    "    if not os.path.exists(raw_dataset_path):\n",
    "        os.makedirs(raw_dataset_path)\n",
    "    \n",
    "    # Extracting dataset to the intended folder path.\n",
    "    zip_ref = zipfile.ZipFile(dataset_zipped_path, 'r')\n",
    "    zip_ref.extractall(raw_dataset_path)\n",
    "    zip_ref.close()\n",
    "    \n",
    "    # Determining and returning final path of the raw dataset.\n",
    "    dirlist = os.listdir(raw_dataset_path)    \n",
    "    return raw_dataset_path + dirlist[0] + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiKkFog5rchJ"
   },
   "outputs": [],
   "source": [
    "# Function for grayscale check of an image. Returns True if grayscale, False if not.\n",
    "# im:            PIL.Image object, input image\n",
    "# return value:  boolean, True if grayscale, False if not grayscale\n",
    "def is_gray_scale(im):\n",
    "    w,h = im.size\n",
    "    # Generating 10 random pixel coordinate.\n",
    "    rand_pixel_array = np.zeros((10,2))\n",
    "    for i in range(10):\n",
    "        rand_pixel_array[i,:] = [random.randint(0,w-1), random.randint(0,h-1)]\n",
    "    # If all of the 10 pixels have the same values on each channels, the image is regarded grayscale.\n",
    "    for i in range(10):\n",
    "        r,g,b = im.getpixel((rand_pixel_array[i,0], rand_pixel_array[i,1]))\n",
    "        if r != g != b: return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnLN6BlwrchQ"
   },
   "outputs": [],
   "source": [
    "# Function for dimension check of an image. Returns True if if image has the proper dimensions (3D, 3 channels), False if not.\n",
    "# im:            PIL.Image object, input image\n",
    "# return value:  boolean, True if image has the proper dimensions (3D, 3 channels), False if not\n",
    "def has_proper_dim(im):\n",
    "    # Get the image data to numpy array.\n",
    "    im_array = np.array(im)\n",
    "    shape = im_array.shape\n",
    "    # The image shall have 3 dimensions, and 3 channels.\n",
    "    if((len(shape) != 3) or (shape[2] != 3)):\n",
    "        return False\n",
    "    else:\n",
    "        return True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0HC9YGKrche"
   },
   "outputs": [],
   "source": [
    "# Function for making the images to 1:1 ratio, and resizing them to the target size.\n",
    "# im:           PIL.Image object, input image\n",
    "# target_size:  tuple with 2 integer element, (width, height)\n",
    "# return value: PIL.Image object, transformed image\n",
    "def crop_resize_Image(im, target_size):\n",
    "    # Taking out the image data (width,height).\n",
    "    width,height = im.size\n",
    "    # Deciding if the image is landscape or portrait.\n",
    "    if(width > height):\n",
    "        # Landscape\n",
    "        top     = 0\n",
    "        left    = int((width - height)/2)\n",
    "        bottom  = height\n",
    "        right    = width - int((width - height)/2)\n",
    "    else:\n",
    "        # Portrait.\n",
    "        top     = int((height - width)/2)\n",
    "        left    = 0\n",
    "        bottom  = height-int((height - width)/2)\n",
    "        right    = width\n",
    "    # Cropping the image to conform 1:1 ratio, the resizing to target size.\n",
    "    return im.crop((left,top,right,bottom)).resize(target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gi5IYfxjrchp"
   },
   "outputs": [],
   "source": [
    "# Function for standardizing the input array.\n",
    "# array:          numpy array, input array\n",
    "# return value:   numpy array, standardized input array\n",
    "def standardize(array):\n",
    "    # Calculating average on all elements of the array.\n",
    "    ave = np.average(array)\n",
    "    # Calculating standard deviation on all the elements of the array.\n",
    "    std = np.std(array)\n",
    "    # Standardizing the input array.\n",
    "    new_array = (array-ave)/std\n",
    "    # Returning standardized array.\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5eRidPZrch4"
   },
   "outputs": [],
   "source": [
    "# Function for transforming the images of the dataset to 1:1 ratio, and target size.\n",
    "# initial_path:  String, folder path of the raw dataset\n",
    "# target_path:   String, intended folder path of the transformed dataset\n",
    "# image_size:    tuple with 2 integer element, (width, height)\n",
    "def dataset_transform(initial_path, target_path, image_size):\n",
    "    # Creating directory for the transformed dataset, if it does not exist.\n",
    "    if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "    # Iterating over the raw images.\n",
    "    for filename in os.listdir(initial_path):\n",
    "        im = Image.open(initial_path + filename)\n",
    "        # Filtering out the grayscale images, and images with improper dimensions.\n",
    "        if((is_gray_scale(im) == False) and (has_proper_dim(im) == True)):\n",
    "            # Making the images to 1:1 ratio, and resizing them to the target size.\n",
    "            im = crop_resize_Image(im,(128,128))\n",
    "            # Saving the images to the target directory.\n",
    "            im.save(target_path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rKOEjBXrciD"
   },
   "outputs": [],
   "source": [
    "# Function to preprocess the given number of images from the given offset to form training and validation data.\n",
    "# dataset_path:  String, folder path of the dataset\n",
    "# train_spl:     float, proportion of training data to all data\n",
    "# valid_spl:     float, proportion of validation data to all data\n",
    "# num_imgs:      int, number of images to preprocess\n",
    "# offset:        int, image index offset in dataset folder\n",
    "# return value:  training data input, training data output, validation data input, validation data output\n",
    "def preprocess_train_valid_data(dataset_path, train_spl, valid_spl, num_imgs, offset):\n",
    "    \n",
    "    # Determine validation split when taking to account only training and validation data.\n",
    "    valid_split = valid_spl / (train_spl + valid_spl)\n",
    "    \n",
    "    # Making a list of filenames of the dataset directory.\n",
    "    filename_list = os.listdir(dataset_path)\n",
    "    # Creating an empty list for the loaded images.\n",
    "    data = []\n",
    "    # Iterating over the given number of images from the given offset in the dataset.\n",
    "    for i in range(offset, (offset + num_imgs)):\n",
    "        # Loading the actual image, then converting that to a numpy array.\n",
    "        csv = np.genfromtxt(dataset_path + filename_list[i], delimiter=',')\n",
    "        image = csv.reshape(128,128,3)\n",
    "        # Appending image to the list.\n",
    "        data.append(image)  \n",
    "\n",
    "    # Creating a numpy array from the list, with float32 datatype.\n",
    "    data = np.asarray(data, dtype='float32')\n",
    "    # Selecting the first channel of the images as input, that contains the grayscale representation of the image in lAB color space.\n",
    "    X = data[:,:,:,0]\n",
    "    # Selecting the second and third channels of the images as output, they contain green–red and blue–yellow color components respectively.\n",
    "    Y = data[:,:,:,1:]\n",
    "    \n",
    "    # Selecting training and validation data separately.    \n",
    "    X_train = X[0:int(num_imgs*(1-valid_split)),:,:]\n",
    "    Y_train = Y[0:int(num_imgs*(1-valid_split)),:,:,:]\n",
    "    X_valid = X[int(num_imgs*(1-valid_split)):,:,:]\n",
    "    Y_valid = Y[int(num_imgs*(1-valid_split)):,:,:,:]\n",
    "    \n",
    "    return X_train,Y_train,X_valid,Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_MX25K1rciR"
   },
   "outputs": [],
   "source": [
    "# Function to preprocess the given number of images from the given offset to form test data.\n",
    "# dataset_path:  String, folder path of the dataset\n",
    "# num_imgs:      int, number of images to preprocess\n",
    "# offset:        int, image index offset in dataset folder\n",
    "# return value:  test data input, test data output\n",
    "def preprocess_test_data(dataset_path, num_imgs, offset):\n",
    "    \n",
    "    # Making a list of filenames of the dataset directory.\n",
    "    filename_list = os.listdir(dataset_path)\n",
    "    # Creating an empty list for the loaded images.\n",
    "    data = []\n",
    "    # Iterating over the given number of images from the given offset in the dataset.\n",
    "    for i in range(offset, min(offset + num_imgs,len(filename_list))):\n",
    "        # Loading the actual image, then converting that to a numpy array.\n",
    "        csv = np.genfromtxt(dataset_path + filename_list[i], delimiter=',')\n",
    "        image = csv.reshape(128,128,3)\n",
    "        # Appending image to the list.\n",
    "        data.append(image) \n",
    "\n",
    "    # Creating a numpy array from the list, with float32 datatype.\n",
    "    data = np.asarray(data, dtype='float32')\n",
    "    # Selecting the first channel of the images as input, that contains the grayscale representation of the image in lAB color space.\n",
    "    X_test = data[:,:,:,0]\n",
    "    # Selecting the second and third channels of the images as output, they contain green–red and blue–yellow color components respectively.\n",
    "    Y_test = data[:,:,:,1:]\n",
    "    \n",
    "    return X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3ir1wqircig"
   },
   "outputs": [],
   "source": [
    "# Function for converting RGB image array to grayscale image array.\n",
    "def img_grayscale(imageArray):\n",
    "    \n",
    "    imgArr= np.empty([1])\n",
    "    for image in imageArray:\n",
    "        pil_imgray = image.convert('LA')\n",
    "        img = np.array(list(pil_imgray.getdata(band=0)), int)\n",
    "        img.shape = (pil_imgray.size[1], pil_imgray.size[0])\n",
    "        imgArr=np.append(imgArr,img)\n",
    "    imgArr = np.delete(imgArr,0)\n",
    "    imgArr.shape = (len(imageArray),pil_imgray.size[1], pil_imgray.size[0])\n",
    "    return imgArr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbBnLINnrciu"
   },
   "outputs": [],
   "source": [
    "# Function for making visualization for the images.\n",
    "# transformed_dataset_path   String, folder path of transformed dataset\n",
    "# width                      int, number of images on one edge\n",
    "# size                       int, size of 1:1 ratio image\n",
    "def image_mosaic(transformed_dataset_path, width, size):\n",
    "    \n",
    "    # Making a list of filenames of the dataset directory.\n",
    "    filename_list = os.listdir(transformed_dataset_path)\n",
    "    # Creating an empty list for the loaded images.\n",
    "    imagearray = []\n",
    "    # Loading the first width*width number of images, and appending them to the list.\n",
    "    for i in range(width*width):\n",
    "        im = Image.open(transformed_dataset_path + filename_list[i])\n",
    "        imagearray.append(im)\n",
    "        \n",
    "    # Initializing canvas.\n",
    "    canvas = np.ones((size*width,size*width*2,3));\n",
    "    # Resizing images.\n",
    "    for i in range(len(imagearray)):\n",
    "        imagearray[i]=imagearray[i].resize((size,size),Image.ANTIALIAS)\n",
    "    # Making GrayImages.\n",
    "    grayimage=img_grayscale(imagearray)\n",
    "    # Writing the RGB images to the canvas right side.\n",
    "    for i in range(width):\n",
    "        for j in range(width):\n",
    "            canvas[i*size:(i+1)*size,j*size:(j+1)*size,0::]=np.array(imagearray[i+width*j])\n",
    "    # Writing grayscale images to the canvas left side.\n",
    "    for i in range(width):\n",
    "        for j in range(width,2*width):\n",
    "            canvas[i*size:(i+1)*size,j*size:(j+1)*size,0]=np.array(grayimage[i+width*(j-width)])\n",
    "            canvas[i*size:(i+1)*size,j*size:(j+1)*size,1]=np.array(grayimage[i+width*(j-width)])\n",
    "            canvas[i*size:(i+1)*size,j*size:(j+1)*size,2]=np.array(grayimage[i+width*(j-width)])\n",
    "            \n",
    "    # Displaying the mosaic.\n",
    "    canvas = canvas.astype(np.uint8);\n",
    "    mosaic = Image.fromarray(canvas)\n",
    "    mosaic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class TrainingHistory\n",
    "class TrainingHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses=[]\n",
    "        self.valid_losses =[]\n",
    "        self.accs = []\n",
    "        self.valid_accs = []\n",
    "        self.epoch=0\n",
    "    \n",
    "    def on_epoch_end(self, epoch,logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.valid_losses.append(logs.get('val_loss'))\n",
    "        self.accs.append(logs.get('acc'))\n",
    "        self.valid_accs.append(logs.get('val_acc'))\n",
    "        self.epoch += 1\n",
    "#Initializing the history  \n",
    "history = TrainingHistory()\n",
    "\n",
    "#Defining the earlystopping\n",
    "es = EarlyStopping(patience=10, verbose=1)\n",
    "mcp = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the neural network model.\n",
    "model = Sequential();\n",
    "model.add(Conv2D(data_format=\"channels_first\",input_shape=(128, 128,1), filters=32, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=32, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=32, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=128, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=128, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=128, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(1024, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Dense(2*128*128, activation='linear'))\n",
    "model.add(Activation('sigmoid'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkIhjs2kpKvG"
   },
   "outputs": [],
   "source": [
    "# Specifying train, validation and test split values.\n",
    "train_split = 0.8\n",
    "valid_split = 0.1\n",
    "test_split = 0.1\n",
    "# Specifying intended filepath for the dataset to be downloaded.\n",
    "dataset_zipped_path = os.getcwd() + '/zipped_dataset.zip'\n",
    "# Specifying intended folder path of raw dataset.\n",
    "raw_dataset_path = os.getcwd() + '/raw_dataset/'\n",
    "# Specifying intended folder path of transformed dataset.\n",
    "transformed_dataset_path = 'C:/Users/USER/Documents/datasets/transformed_dataset/'\n",
    "# Specifying intended folder for standardized dataset.\n",
    "csv_dataset_path ='E:/Deep_Learning_HW/csv_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying input image size.\n",
    "image_size = (128,128)\n",
    "# Specifying maximal number of images that can be loaded into memory at one time.\n",
    "max_loaded_imgs_num = 1000\n",
    "\n",
    "print('Start zip file download. '+str(datetime.datetime.now()))\n",
    "# Downloading zipped dataset.\n",
    "download_dataset('https://datasets.figure-eight.com/figure_eight_datasets/open-images/test_challenge.zip', dataset_zipped_path)\n",
    "print('Zip file downloaded. '+str(datetime.datetime.now()))\n",
    "\n",
    "print('Start images extraction. '+str(datetime.datetime.now()))\n",
    "# Extracting zipped dataset to the intended folder path.\n",
    "raw_dataset_path = extract_dataset(dataset_zipped_path, raw_dataset_path)\n",
    "print('Images are extracted. '+str(datetime.datetime.now()))\n",
    "\n",
    "print('Start dataset transforming. '+str(datetime.datetime.now()))\n",
    "# Transforming raw dataset to the proper format. \n",
    "dataset_transform(raw_dataset_path, transformed_dataset_path, (128,128))\n",
    "print('Dataset is transformed. '+str(datetime.datetime.now()))\n",
    "\n",
    "print('Start calculating average and std value on train data. '+str(datetime.datetime.now()))\n",
    "std,ave = dataset_std(transformed_dataset_path,128,valid_split,test_split)\n",
    "print('Calculated average and std value, '+str(datetime.datetime.now()))\n",
    "\n",
    "print('Start transforming images to csv files. '+str(datetime.datetime.now()))\n",
    "dataset_normalized_csv(transformed_dataset_path,csv_dataset_path,ave,std)\n",
    "print('Transformed images to csv files. '+str(datetime.datetime.now()))\n",
    "\n",
    "# Visualization dataset by displaying a mosaic.\n",
    "image_mosaic(transformed_dataset_path, 10, 64)\n",
    "\n",
    "# Determining the length of the dataset.\n",
    "len_dataset = len(os.listdir(transformed_dataset_path))\n",
    "\n",
    "# Since the whole dataset cannot be loaded to the memory at the same time, the training of the network will be\n",
    "# executed in cycles. In each cycle (except the last) a predetermined number of images (max_loaded_imgs_num) are\n",
    "# loaded to the memory, where they are preprocessed and split to training and validation datasets. Then epoch\n",
    "# number of training and validation phase are executed on the neural network with these datasets. The images\n",
    "# loaded to the memory are different in every cycle.\n",
    "\n",
    "# Determining the combined length of the training and validation data.\n",
    "len_train_val_set = (int)(len_dataset*(train_split+valid_split))\n",
    "# Determinde number of (training + validation) cycles.\n",
    "num_cycles_train_val = (int)(len_train_val_set/max_loaded_imgs_num) + 1\n",
    "# Determine the length of the last section of (training + validation) data.\n",
    "len_last_section_train_val = len_train_val_set - max_loaded_imgs_num * (num_cycles_train_val - 1)\n",
    "\n",
    "# Since the whole dataset cannot be loaded to the memory at the same time, the network evaluation on test data\n",
    "# will be executed in cycles. In each cycle (except the last) a predetermined number of images (max_loaded_imgs_num)\n",
    "# are loaded to the memory, where they are preprocessed, forming the test dataset. Then the test phase is executed\n",
    "# on the neural network with this dataset. The images loaded to the memory are different in every cycle.\n",
    "\n",
    "# Determining the length of the test data.\n",
    "len_test_set = len_dataset - len_train_val_set\n",
    "# Determinde number of test cycles.\n",
    "num_cycles_test = (int)(len_test_set/max_loaded_imgs_num) + 1\n",
    "# Determine the length of the last section of test data.\n",
    "len_last_section_test = len_test_set - max_loaded_imgs_num * (num_cycles_test - 1)\n",
    "\n",
    "# Execution of (num_cycles_train_val-1) training cycle.\n",
    "#for i in range(num_cycles_train_val-1):\n",
    "#    (X_train,Y_train,X_valid,Y_valid) = preprocess_train_valid_data(transformed_dataset_path, train_split, valid_split, max_loaded_imgs_num, i * max_loaded_imgs_num)\n",
    "    # training the model\n",
    "\n",
    "# If there are images left in the last section, execute last training cycle.\n",
    "#if(len_last_section_train_val != 0):    \n",
    "#    (X_train,Y_train,X_valid,Y_valid) = preprocess_train_valid_data(transformed_dataset_path, train_split, valid_split, len_last_section_train_val, (num_cycles_train_val - 1) * max_loaded_imgs_num)\n",
    "    # training the model\n",
    "\n",
    "# Execution of (num_cycles_test-1) test cycle.\n",
    "#for i in range(num_cycles_test-1):\n",
    "#    (X_test, Y_test) = preprocess_test_data(transformed_dataset_path, max_loaded_imgs_num, len_train_val_set + i * max_loaded_imgs_num )\n",
    "    # elvaluation of test data\n",
    "\n",
    "# If there are images left in the last section, execute last test cycle.\n",
    "#if(len_last_section_test != 0):\n",
    "#    (X_test, Y_test) = preprocess_test_data(transformed_dataset_path, len_last_section_test, len_train_val_set + (num_cycles_test - 1) * max_loaded_imgs_num )\n",
    "    # evaluation of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vd-wkdfOuGv3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 888 samples, validate on 112 samples\n",
      "Epoch 1/10\n",
      " - 331s - loss: 210636.9569 - val_loss: 209126.8870\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 209126.88700, saving model to weights.hdf5\n",
      "Epoch 2/10\n",
      " - 328s - loss: 210788.7349 - val_loss: 209126.8870\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 209126.88700\n",
      "Epoch 3/10\n",
      " - 319s - loss: 210788.7349 - val_loss: 209126.8870\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 209126.88700\n",
      "Epoch 4/10\n",
      " - 331s - loss: 210788.7349 - val_loss: 209126.8870\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 209126.88700\n",
      "Epoch 5/10\n",
      " - 326s - loss: 210788.7349 - val_loss: 209126.8870\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 209126.88700\n",
      "Epoch 6/10\n",
      " - 329s - loss: 210788.7349 - val_loss: 209126.8870\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 209126.88700\n",
      "Epoch 7/10\n",
      " - 320s - loss: 210788.7349 - val_loss: 209126.8870\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 209126.88700\n",
      "Epoch 8/10\n",
      " - 322s - loss: 210788.7349 - val_loss: 209126.8870\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 209126.88700\n",
      "Epoch 9/10\n",
      " - 329s - loss: 210788.7349 - val_loss: 209126.8870\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 209126.88700\n",
      "Epoch 10/10\n",
      " - 319s - loss: 210788.7349 - val_loss: 209126.8870\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 209126.88700\n"
     ]
    }
   ],
   "source": [
    "sgd=SGD(lr=1, momentum=0.09, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "(X_train,Y_train,X_valid,Y_valid) = preprocess_train_valid_data(csv_dataset_path, train_split, valid_split, 1000, 0)\n",
    "\n",
    "hst = model.fit(X_train.reshape((-1,128,128,1)), Y_train.reshape((-1,2*128*128)),\\\n",
    "         batch_size=1,\n",
    "         epochs=10,\n",
    "         verbose=2,\n",
    "         validation_data=(X_valid.reshape((-1,128,128,1)),Y_valid.reshape((-1,2*128*128))),\n",
    "         callbacks=[mcp, es, history],\n",
    "         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h31DKQZbuS10"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.title(\"Hiba mértéke a tanítás során\")\n",
    "plt.plot(np.arange(history.epoch), history.losses, color='g',  \n",
    "         label=\"Hiba a tanító adatokon\")\n",
    "plt.plot(np.arange(history.epoch), history.valid_losses, color='r',\n",
    "         label=\"Hiba a validációs adatokon\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Epochok száma\")\n",
    "plt.ylabel(\"Hiba\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 3086 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 13941 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 7487 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 4804 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 10553 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 8035 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 13576 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 13798 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 11723 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9413 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 12757 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 8112 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 10266 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9774 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 7416 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 13652 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 6719 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9561 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 15062 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 12003 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9469 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 6766 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 3903 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 5673 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 11105 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 11847 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9386 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 3264 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 15205 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 13778 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9560 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9624 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9045 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 4643 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 15076 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 12865 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 1284 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 11447 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 6946 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 12619 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9103 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 4980 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 7545 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 10536 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 6568 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 7441 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 10157 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9048 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 6301 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 3495 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 1911 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 7585 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 6839 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 15196 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 5141 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 14573 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 4493 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 10359 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9506 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 14393 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 7153 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 4784 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 10167 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 15102 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 13136 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9302 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 14183 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 6169 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 10487 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 10604 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 13819 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 6521 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9196 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 6843 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 12512 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 13111 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 2594 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 5552 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 8697 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 13921 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 10144 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9248 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 8409 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 14630 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9270 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 11809 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 11545 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 13847 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 5843 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 2787 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 5776 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 14316 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 8837 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9512 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 9376 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 13602 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 3292 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 12977 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\skimage\\color\\colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 8633 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    }
   ],
   "source": [
    "std = 28.18332749171332\n",
    "ave = 47.16514176432521\n",
    "mosaic_width = 10;\n",
    "size = 128;\n",
    "num_imgs = mosaic_width*mosaic_width;\n",
    "(X_test, Y_test) = preprocess_test_data(csv_dataset_path, num_imgs , 8000)\n",
    "preds = model.predict(X_test.reshape((-1,128,128,1)))\n",
    "preds = preds.reshape((-1,128,128,2))\n",
    "original_images = np.empty((num_imgs,128,128,3), dtype = 'float64')\n",
    "predicted_images = np.empty((num_imgs,128,128,3), dtype = 'float64')\n",
    "gray_channel = X_test * std + ave\n",
    "original_images[:,:,:,0] = gray_channel;\n",
    "predicted_images[:,:,:,0] = gray_channel;\n",
    "\n",
    "color_channels_original = Y_test * 255 -128\n",
    "original_images[:,:,:,1:] = color_channels_original;\n",
    "\n",
    "color_channels_predicted = preds * 255 - 128\n",
    "predicted_images[:,:,:,1:] = color_channels_predicted;\n",
    "\n",
    "for i in range (num_imgs):\n",
    "    original_images[i,:,:,:] = skcolor.lab2rgb(original_images[i,:,:,:])\n",
    "    predicted_images[i,:,:,:] = skcolor.lab2rgb(predicted_images[i,:,:,:])\n",
    "    \n",
    "im = k_image.array_to_img(predicted_images[5,:,:,:])\n",
    "im.show()\n",
    "im = k_image.array_to_img(original_images[5,:,:,:])\n",
    "im.show()\n",
    "    \n",
    "original_images.astype('uint8')\n",
    "predicted_images.astype('uint8')\n",
    "    \n",
    "# Initializing canvas.\n",
    "canvas = np.zeros((size*mosaic_width,size*mosaic_width*2,3), dtype = 'uint8');\n",
    "# Writing the RGB images to the canvas right side.\n",
    "for i in range(mosaic_width):\n",
    "    for j in range(mosaic_width):\n",
    "        canvas[i*size:(i+1)*size,j*size:(j+1)*size,:]= original_images[i*mosaic_width+j,:,:,:]\n",
    "# Writing grayscale images to the canvas left side.\n",
    "for i in range(mosaic_width):\n",
    "    for j in range(mosaic_width,2*mosaic_width):\n",
    "        canvas[i*size:(i+1)*size,j*size:(j+1)*size,:]= predicted_images[i*mosaic_width+(j-mosaic_width),:,:,:]\n",
    "\n",
    "# Displaying the mosaic.\n",
    "canvas = canvas.astype(np.uint8);\n",
    "mosaic = Image.fromarray(canvas)\n",
    "#mosaic = k_image.array_to_img(canvas)\n",
    "mosaic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_origi = original_images[0,:,:,:]\n",
    "img_predi = predicted_images[0,:,:,:]\n",
    "\n",
    "img_origi = skcolor.lab2rgb(img_origi)\n",
    "img_predi = skcolor.lab2rgb(img_predi)\n",
    "\n",
    "im = k_image.array_to_img(img_origi)\n",
    "im.show()\n",
    "\n",
    "im = k_image.array_to_img(img_predi)\n",
    "im.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ColorNet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
