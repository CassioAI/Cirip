{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9qBI03FrcgL"
   },
   "source": [
    "#  A short introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oCPtUo00rcgQ"
   },
   "source": [
    "We are working on a project to color grayscale pictures.\n",
    "The first few aspect of our project that we would like to introduce in this short introduction, are the decisions we took in our current approach to the problem.\n",
    "\n",
    "The Dataset:\n",
    "At first we were planning on using the ImageNet Database, but soon it became evident, that due to some technical difficulties on the site we weren't going to get access, so we decided on our current Database (Open Images V4 Dataset) which granted us the original images in a zip file. The images are not restricted to a single subject, the dataset incorporates images with various themes. We decided to start with 100000 images.\n",
    "(https://www.figure-eight.com/dataset/open-images-annotated-with-bounding-boxes/)\n",
    "\n",
    "The Images:\n",
    "Although the Images in the Database were mostly satisfactory for our goals, there were some modifications we had to make on them. Since the images were too big for us to handle and they did not have the same measurements we decided to crop them into a square shape and scale them down to resolution of 128X128. Also some of the pictures were not appropriate for our task such as grayscale pictures, so we decided, to sort them out.\n",
    "\n",
    "The LAB color scale:\n",
    "We decided to convert the images from RGB color space to LAB, which hopefully will make the teaching easier, as the L channel of LAB colorspace is the greyscale representation of the image, so the machine will only have to predict two channels instead of 3.\n",
    "\n",
    "The Small Parts:\n",
    "Even with a 128X128 scaling the whole dataset is too big to be loaded to the operating memory as a numpy array, so we decided to divide it into smaller parts, and teach the neural network on each smaller part individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m79XKvNKrcgY"
   },
   "source": [
    "# The preparation and preprocessing of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XesJ2Jrcrcgi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the used packages\n",
    "# Numpy for arrays\n",
    "import numpy as np\n",
    "# requests for downloading the dataset\n",
    "import requests\n",
    "# PIL.Image for image processing\n",
    "from PIL import Image\n",
    "# keras.preprocessing.image for image processing\n",
    "import keras.preprocessing.image as k_image\n",
    "# os for file management\n",
    "import os\n",
    "# skimage.color for transforming the color model of images\n",
    "import skimage.color as skcolor\n",
    "# zipfile for extracting downloaded dataset \n",
    "import zipfile\n",
    "# random for random number generation in grayscale check\n",
    "import random\n",
    "\n",
    "import math\n",
    "\n",
    "import datetime\n",
    "#from google.colab import drive\n",
    "# Importing the used packages\n",
    "## Numpy for arrays\n",
    "import numpy as np\n",
    "## Pyplot from Matplotlib for vizualising the test results in plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "## Math for Sqrt\n",
    "import math\n",
    "## Drive from Google.Colab because I was storing my database in google drive\n",
    "#from google.colab import drive\n",
    "## Genfromtxt to convert our csv file to array\n",
    "from numpy import genfromtxt\n",
    "## Keras.* for building my fully connected dense neural network \n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation,Flatten\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import SGD\n",
    "## Mean_squared_error from sklearn.metrics for calculating mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "## keras.callbacks.* for Earlystopping (modelcheckpoint is needed to load back the weights)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "YM-AHGITlwau",
    "outputId": "020f7d40-26fe-4aef-d647-c6803dd911e3"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive', force_remount=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CoQZxGOl9S9"
   },
   "outputs": [],
   "source": [
    "#Function for converting RGB images from path to LAB images.\n",
    "# path:          String, filepath of the images\n",
    "# return value:  Float array 128x128x3, The array of the images in LAB colorization\n",
    "def path2labimage(path):\n",
    "  #Opening the image from path and converting it to float array\n",
    "  raw_image_array = np.array(Image.open(path)).astype('float32')\n",
    "  #Converting RGB image to LAB\n",
    "  image_array = skcolor.rgb2lab(raw_image_array/255)\n",
    "  #Returning the float array with the LAB image values\n",
    "  return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRwOLPyJhDWZ"
   },
   "outputs": [],
   "source": [
    "#Function for normalizing the images and saving it to csv files.\n",
    "# initial_path:          String, filepath of the images\n",
    "# target_path:           String, intended folder path of csv files\n",
    "# array_average:         Int, the average value of the train dataset\n",
    "# array_std:             Int, the standard deviation value of the train dataset\n",
    "def dataset_normalized_csv(initial_path,target_path,array_average,array_std):\n",
    "    # Creating directory for the transformed dataset, if it does not exist.\n",
    "    if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "        \n",
    "    i=0\n",
    "    t1=datetime.datetime.now()\n",
    "    # Iterating over the raw images.\n",
    "    for filename in os.listdir(initial_path):\n",
    "        t2 = datetime.datetime.now()\n",
    "        if(t2.minute != t1.minute):\n",
    "            print(str(i)+'/'+str(len(os.listdir(initial_path))))\n",
    "            t1=t2\n",
    "        \n",
    "        i+=1\n",
    "        #Converting path to LAB image\n",
    "        image_array = path2labimage(initial_path + filename)\n",
    "        #Normalizing the grayimage\n",
    "        image_array[:,:,0] = (image_array[:,:,0]-array_average)/array_std\n",
    "        #Min max scaling the color dimensions\n",
    "        image_array[:,:,1::] = image_array[:,:,1::]+128\n",
    "        image_array[:,:,1::] = image_array[:,:,1::]/256\n",
    "        #Saving to a csv files\n",
    "        np.savetxt((target_path + filename[:-3] + 'csv'), image_array.reshape((-1,3)), delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEww1VNChD8I"
   },
   "outputs": [],
   "source": [
    "def dataset_std(initial_path, image_size, valid_split, test_split):\n",
    "    NA = image_size*image_size;\n",
    "    NB = 0;\n",
    "    SA = 0;\n",
    "    SB = 'a';\n",
    "    a_ave = 0;\n",
    "    b_ave = 0;\n",
    "    i = 0;\n",
    "    t1=datetime.datetime.now()\n",
    "    for filename in os.listdir(initial_path):\n",
    "\n",
    "        t2 = datetime.datetime.now()\n",
    "        if(t2.minute != t1.minute):\n",
    "            print(str(i)+'/'+str(len(os.listdir(initial_path))))\n",
    "            t1=t2\n",
    "\n",
    "        image_array = path2labimage(initial_path + filename)\n",
    "        SA = np.std(image_array[:,:,0])\n",
    "        a_ave = np.average(image_array[:,:,0])\n",
    "        if(SB=='a'):\n",
    "            SB = SA\n",
    "            NB += NA\n",
    "            b_ave = a_ave;\n",
    "        else:\n",
    "            SB =math.sqrt(((NA-1)*(SA**2)+(NB-1)*(SB**2)+NA*NB/(NA+NB)*math.pow(a_ave-b_ave,2))/(NA+NB-1))\n",
    "            b_ave = (b_ave*NB+a_ave*NA)/(NB+NA)\n",
    "            NB += NA\n",
    "\n",
    "     #   if( i >= int(len(os.listdir(initial_path))*(1-valid_split-test_split))):\n",
    "     #     return SB,b_ave\n",
    "        i += 1\n",
    "    return  SB,b_ave   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2pMnKBhrcgv"
   },
   "outputs": [],
   "source": [
    "# Function for downloading the dataset.\n",
    "# url:           String, url of the zipped dataset\n",
    "# target_path:   String, intended filepath of the downloaded dataset\n",
    "def download_dataset(url, target_path):\n",
    "    # Downloading the file in chunks to avoid memory overrun.\n",
    "    r = requests.get(url, stream = True)\n",
    "    with open(target_path, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            # Filtering out keep-alive new chunks.\n",
    "            if chunk: \n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cX7THU6Crcg9"
   },
   "outputs": [],
   "source": [
    "#Function for extracting zipped dataset.\n",
    "# dataset_zipped_path:   String, filepath of the zipped dataset\n",
    "# raw_dataset_path:      String, intended folder path of raw dataset\n",
    "# return value:          String, final folder path of raw dataset\n",
    "def extract_dataset(dataset_zipped_path, raw_dataset_path):\n",
    "    # Creating directory for the raw dataset, if it does not exist.\n",
    "    if not os.path.exists(raw_dataset_path):\n",
    "        os.makedirs(raw_dataset_path)\n",
    "    \n",
    "    # Extracting dataset to the intended folder path.\n",
    "    zip_ref = zipfile.ZipFile(dataset_zipped_path, 'r')\n",
    "    zip_ref.extractall(raw_dataset_path)\n",
    "    zip_ref.close()\n",
    "    \n",
    "    # Determining and returning final path of the raw dataset.\n",
    "    dirlist = os.listdir(raw_dataset_path)    \n",
    "    return raw_dataset_path + dirlist[0] + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiKkFog5rchJ"
   },
   "outputs": [],
   "source": [
    "# Function for grayscale check of an image. Returns True if grayscale, False if not.\n",
    "# im:            PIL.Image object, input image\n",
    "# return value:  boolean, True if grayscale, False if not grayscale\n",
    "def is_gray_scale(im):\n",
    "    w,h = im.size\n",
    "    # Generating 10 random pixel coordinate.\n",
    "    rand_pixel_array = np.zeros((10,2))\n",
    "    for i in range(10):\n",
    "        rand_pixel_array[i,:] = [random.randint(0,w-1), random.randint(0,h-1)]\n",
    "    # If all of the 10 pixels have the same values on each channels, the image is regarded grayscale.\n",
    "    for i in range(10):\n",
    "        r,g,b = im.getpixel((rand_pixel_array[i,0], rand_pixel_array[i,1]))\n",
    "        if r != g != b: return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnLN6BlwrchQ"
   },
   "outputs": [],
   "source": [
    "# Function for dimension check of an image. Returns True if if image has the proper dimensions (3D, 3 channels), False if not.\n",
    "# im:            PIL.Image object, input image\n",
    "# return value:  boolean, True if image has the proper dimensions (3D, 3 channels), False if not\n",
    "def has_proper_dim(im):\n",
    "    # Get the image data to numpy array.\n",
    "    im_array = np.array(im)\n",
    "    shape = im_array.shape\n",
    "    # The image shall have 3 dimensions, and 3 channels.\n",
    "    if((len(shape) != 3) or (shape[2] != 3)):\n",
    "        return False\n",
    "    else:\n",
    "        return True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0HC9YGKrche"
   },
   "outputs": [],
   "source": [
    "# Function for making the images to 1:1 ratio, and resizing them to the target size.\n",
    "# im:           PIL.Image object, input image\n",
    "# target_size:  tuple with 2 integer element, (width, height)\n",
    "# return value: PIL.Image object, transformed image\n",
    "def crop_resize_Image(im, target_size):\n",
    "    # Taking out the image data (width,height).\n",
    "    width,height = im.size\n",
    "    # Deciding if the image is landscape or portrait.\n",
    "    if(width > height):\n",
    "        # Landscape\n",
    "        top     = 0\n",
    "        left    = int((width - height)/2)\n",
    "        bottom  = height\n",
    "        right    = width - int((width - height)/2)\n",
    "    else:\n",
    "        # Portrait.\n",
    "        top     = int((height - width)/2)\n",
    "        left    = 0\n",
    "        bottom  = height-int((height - width)/2)\n",
    "        right    = width\n",
    "    # Cropping the image to conform 1:1 ratio, the resizing to target size.\n",
    "    return im.crop((left,top,right,bottom)).resize(target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gi5IYfxjrchp"
   },
   "outputs": [],
   "source": [
    "# Function for standardizing the input array.\n",
    "# array:          numpy array, input array\n",
    "# return value:   numpy array, standardized input array\n",
    "def standardize(array):\n",
    "    # Calculating average on all elements of the array.\n",
    "    ave = np.average(array)\n",
    "    # Calculating standard deviation on all the elements of the array.\n",
    "    std = np.std(array)\n",
    "    # Standardizing the input array.\n",
    "    new_array = (array-ave)/std\n",
    "    # Returning standardized array.\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5eRidPZrch4"
   },
   "outputs": [],
   "source": [
    "# Function for transforming the images of the dataset to 1:1 ratio, and target size.\n",
    "# initial_path:  String, folder path of the raw dataset\n",
    "# target_path:   String, intended folder path of the transformed dataset\n",
    "# image_size:    tuple with 2 integer element, (width, height)\n",
    "def dataset_transform(initial_path, target_path, image_size):\n",
    "    # Creating directory for the transformed dataset, if it does not exist.\n",
    "    if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "    # Iterating over the raw images.\n",
    "    for filename in os.listdir(initial_path):\n",
    "        im = Image.open(initial_path + filename)\n",
    "        # Filtering out the grayscale images, and images with improper dimensions.\n",
    "        if((is_gray_scale(im) == False) and (has_proper_dim(im) == True)):\n",
    "            # Making the images to 1:1 ratio, and resizing them to the target size.\n",
    "            im = crop_resize_Image(im,(128,128))\n",
    "            # Saving the images to the target directory.\n",
    "            im.save(target_path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rKOEjBXrciD"
   },
   "outputs": [],
   "source": [
    "# Function to preprocess the given number of images from the given offset to form training and validation data.\n",
    "# dataset_path:  String, folder path of the dataset\n",
    "# train_spl:     float, proportion of training data to all data\n",
    "# valid_spl:     float, proportion of validation data to all data\n",
    "# num_imgs:      int, number of images to preprocess\n",
    "# offset:        int, image index offset in dataset folder\n",
    "# return value:  training data input, training data output, validation data input, validation data output\n",
    "def preprocess_train_valid_data(dataset_path, train_spl, valid_spl, num_imgs, offset):\n",
    "    \n",
    "    # Determine validation split when taking to account only training and validation data.\n",
    "    valid_split = valid_spl / (train_spl + valid_spl)\n",
    "    \n",
    "    # Making a list of filenames of the dataset directory.\n",
    "    filename_list = os.listdir(dataset_path)\n",
    "    # Creating an empty list for the loaded images.\n",
    "    data = []\n",
    "    # Iterating over the given number of images from the given offset in the dataset.\n",
    "    for i in range(offset, (offset + num_imgs)):\n",
    "        # Loading the actual image, then converting that to a numpy array.\n",
    "        csv = np.genfromtxt(dataset_path + filename_list[i], delimiter=',')\n",
    "        image = csv.reshape(128,128,3)\n",
    "        # Appending image to the list.\n",
    "        data.append(image)  \n",
    "\n",
    "    # Creating a numpy array from the list, with float32 datatype.\n",
    "    data = np.asarray(data, dtype='float32')\n",
    "    # Selecting the first channel of the images as input, that contains the grayscale representation of the image in lAB color space.\n",
    "    X = data[:,:,:,0]\n",
    "    # Selecting the second and third channels of the images as output, they contain green–red and blue–yellow color components respectively.\n",
    "    Y = data[:,:,:,1:]\n",
    "    \n",
    "    # Selecting training and validation data separately.    \n",
    "    X_train = X[0:int(num_imgs*(1-valid_split)),:,:]\n",
    "    Y_train = Y[0:int(num_imgs*(1-valid_split)),:,:,:]\n",
    "    X_valid = X[int(num_imgs*(1-valid_split)):,:,:]\n",
    "    Y_valid = Y[int(num_imgs*(1-valid_split)):,:,:,:]\n",
    "    \n",
    "    return X_train,Y_train,X_valid,Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_MX25K1rciR"
   },
   "outputs": [],
   "source": [
    "# Function to preprocess the given number of images from the given offset to form test data.\n",
    "# dataset_path:  String, folder path of the dataset\n",
    "# num_imgs:      int, number of images to preprocess\n",
    "# offset:        int, image index offset in dataset folder\n",
    "# return value:  test data input, test data output\n",
    "def preprocess_test_data(dataset_path, num_imgs, offset):\n",
    "    \n",
    "    # Making a list of filenames of the dataset directory.\n",
    "    filename_list = os.listdir(dataset_path)\n",
    "    # Creating an empty list for the loaded images.\n",
    "    data = []\n",
    "    # Iterating over the given number of images from the given offset in the dataset.\n",
    "    for i in range(offset, min(offset + num_imgs,len(filename_list))):\n",
    "        # Loading the actual image, then converting that to a numpy array.\n",
    "        csv = np.genfromtxt(dataset_path + filename_list[i], delimiter=',')\n",
    "        image = csv.reshape(128,128,3)\n",
    "        # Appending image to the list.\n",
    "        data.append(image) \n",
    "\n",
    "    # Creating a numpy array from the list, with float32 datatype.\n",
    "    data = np.asarray(data, dtype='float32')\n",
    "    # Selecting the first channel of the images as input, that contains the grayscale representation of the image in lAB color space.\n",
    "    X_test = data[:,:,:,0]\n",
    "    # Selecting the second and third channels of the images as output, they contain green–red and blue–yellow color components respectively.\n",
    "    Y_test = data[:,:,:,1:]\n",
    "    \n",
    "    return X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3ir1wqircig"
   },
   "outputs": [],
   "source": [
    "# Function for converting RGB image array to grayscale image array.\n",
    "def img_grayscale(imageArray):\n",
    "    \n",
    "    imgArr= np.empty([1])\n",
    "    for image in imageArray:\n",
    "        pil_imgray = image.convert('LA')\n",
    "        img = np.array(list(pil_imgray.getdata(band=0)), int)\n",
    "        img.shape = (pil_imgray.size[1], pil_imgray.size[0])\n",
    "        imgArr=np.append(imgArr,img)\n",
    "    imgArr = np.delete(imgArr,0)\n",
    "    imgArr.shape = (len(imageArray),pil_imgray.size[1], pil_imgray.size[0])\n",
    "    return imgArr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbBnLINnrciu"
   },
   "outputs": [],
   "source": [
    "# Function for making visualization for the images.\n",
    "# transformed_dataset_path   String, folder path of transformed dataset\n",
    "# width                      int, number of images on one edge\n",
    "# size                       int, size of 1:1 ratio image\n",
    "def image_mosaic(transformed_dataset_path, width, size):\n",
    "    \n",
    "    # Making a list of filenames of the dataset directory.\n",
    "    filename_list = os.listdir(transformed_dataset_path)\n",
    "    # Creating an empty list for the loaded images.\n",
    "    imagearray = []\n",
    "    # Loading the first width*width number of images, and appending them to the list.\n",
    "    for i in range(width*width):\n",
    "        im = Image.open(transformed_dataset_path + filename_list[i])\n",
    "        imagearray.append(im)\n",
    "        \n",
    "    # Initializing canvas.\n",
    "    canvas = np.ones((size*width,size*width*2,3));\n",
    "    # Resizing images.\n",
    "    for i in range(len(imagearray)):\n",
    "        imagearray[i]=imagearray[i].resize((size,size),Image.ANTIALIAS)\n",
    "    # Making GrayImages.\n",
    "    grayimage=img_grayscale(imagearray)\n",
    "    # Writing the RGB images to the canvas right side.\n",
    "    for i in range(width):\n",
    "        for j in range(width):\n",
    "            canvas[i*size:(i+1)*size,j*size:(j+1)*size,0::]=np.array(imagearray[i+width*j])\n",
    "    # Writing grayscale images to the canvas left side.\n",
    "    for i in range(width):\n",
    "        for j in range(width,2*width):\n",
    "            canvas[i*size:(i+1)*size,j*size:(j+1)*size,0]=np.array(grayimage[i+width*(j-width)])\n",
    "            canvas[i*size:(i+1)*size,j*size:(j+1)*size,1]=np.array(grayimage[i+width*(j-width)])\n",
    "            canvas[i*size:(i+1)*size,j*size:(j+1)*size,2]=np.array(grayimage[i+width*(j-width)])\n",
    "            \n",
    "    # Displaying the mosaic.\n",
    "    canvas = canvas.astype(np.uint8);\n",
    "    mosaic = Image.fromarray(canvas)\n",
    "    mosaic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkIhjs2kpKvG"
   },
   "outputs": [],
   "source": [
    "# Specifying train, validation and test split values.\n",
    "train_split = 0.8\n",
    "valid_split = 0.1\n",
    "test_split = 0.1\n",
    "# Specifying intended filepath for the dataset to be downloaded.\n",
    "dataset_zipped_path = os.getcwd() + '/zipped_dataset.zip'\n",
    "# Specifying intended folder path of raw dataset.\n",
    "raw_dataset_path = os.getcwd() + '/raw_dataset/'\n",
    "# Specifying intended folder path of transformed dataset.\n",
    "transformed_dataset_path = 'C:/Users/USER/Documents/datasets/transformed_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1550
    },
    "colab_type": "code",
    "id": "axQbTLTLrci4",
    "outputId": "9ce0b715-2c94-4b27-fd0c-13fc0beeeefa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start zip file download. 2018-11-04 20:36:44.725080\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bf9b71fd7ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start zip file download. '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Downloading zipped dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdownload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://datasets.figure-eight.com/figure_eight_datasets/open-images/test_challenge.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_zipped_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Zip file downloaded. '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a89fa2a2327e>\u001b[0m in \u001b[0;36mdownload_dataset\u001b[0;34m(url, target_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0;31m# Filtering out keep-alive new chunks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Specifying input image size.\n",
    "image_size = (128,128)\n",
    "# Specifying maximal number of images that can be loaded into memory at one time.\n",
    "max_loaded_imgs_num = 1000\n",
    "\n",
    "print('Start zip file download. '+str(datetime.datetime.now()))\n",
    "# Downloading zipped dataset.\n",
    "download_dataset('https://datasets.figure-eight.com/figure_eight_datasets/open-images/test_challenge.zip', dataset_zipped_path)\n",
    "print('Zip file downloaded. '+str(datetime.datetime.now()))\n",
    "\n",
    "print('Start images extraction. '+str(datetime.datetime.now()))\n",
    "# Extracting zipped dataset to the intended folder path.\n",
    "raw_dataset_path = extract_dataset(dataset_zipped_path, raw_dataset_path)\n",
    "print('Images are extracted. '+str(datetime.datetime.now()))\n",
    "\n",
    "print('Start dataset transforming. '+str(datetime.datetime.now()))\n",
    "# Transforming raw dataset to the proper format. \n",
    "dataset_transform(raw_dataset_path, transformed_dataset_path, (128,128))\n",
    "print('Dataset is transformed. '+str(datetime.datetime.now()))\n",
    "\n",
    "# Visualization dataset by displaying a mosaic.\n",
    "image_mosaic(transformed_dataset_path, 10, 64)\n",
    "\n",
    "# Determining the length of the dataset.\n",
    "len_dataset = len(os.listdir(transformed_dataset_path))\n",
    "\n",
    "# Since the whole dataset cannot be loaded to the memory at the same time, the training of the network will be\n",
    "# executed in cycles. In each cycle (except the last) a predetermined number of images (max_loaded_imgs_num) are\n",
    "# loaded to the memory, where they are preprocessed and split to training and validation datasets. Then epoch\n",
    "# number of training and validation phase are executed on the neural network with these datasets. The images\n",
    "# loaded to the memory are different in every cycle.\n",
    "\n",
    "# Determining the combined length of the training and validation data.\n",
    "len_train_val_set = (int)(len_dataset*(train_split+valid_split))\n",
    "# Determinde number of (training + validation) cycles.\n",
    "num_cycles_train_val = (int)(len_train_val_set/max_loaded_imgs_num) + 1\n",
    "# Determine the length of the last section of (training + validation) data.\n",
    "len_last_section_train_val = len_train_val_set - max_loaded_imgs_num * (num_cycles_train_val - 1)\n",
    "\n",
    "# Since the whole dataset cannot be loaded to the memory at the same time, the network evaluation on test data\n",
    "# will be executed in cycles. In each cycle (except the last) a predetermined number of images (max_loaded_imgs_num)\n",
    "# are loaded to the memory, where they are preprocessed, forming the test dataset. Then the test phase is executed\n",
    "# on the neural network with this dataset. The images loaded to the memory are different in every cycle.\n",
    "\n",
    "# Determining the length of the test data.\n",
    "len_test_set = len_dataset - len_train_val_set\n",
    "# Determinde number of test cycles.\n",
    "num_cycles_test = (int)(len_test_set/max_loaded_imgs_num) + 1\n",
    "# Determine the length of the last section of test data.\n",
    "len_last_section_test = len_test_set - max_loaded_imgs_num * (num_cycles_test - 1)\n",
    "\n",
    "# Execution of (num_cycles_train_val-1) training cycle.\n",
    "#for i in range(num_cycles_train_val-1):\n",
    "#    (X_train,Y_train,X_valid,Y_valid) = preprocess_train_valid_data(transformed_dataset_path, train_split, valid_split, max_loaded_imgs_num, i * max_loaded_imgs_num)\n",
    "    # training the model\n",
    "\n",
    "# If there are images left in the last section, execute last training cycle.\n",
    "#if(len_last_section_train_val != 0):    \n",
    "#    (X_train,Y_train,X_valid,Y_valid) = preprocess_train_valid_data(transformed_dataset_path, train_split, valid_split, len_last_section_train_val, (num_cycles_train_val - 1) * max_loaded_imgs_num)\n",
    "    # training the model\n",
    "\n",
    "# Execution of (num_cycles_test-1) test cycle.\n",
    "#for i in range(num_cycles_test-1):\n",
    "#    (X_test, Y_test) = preprocess_test_data(transformed_dataset_path, max_loaded_imgs_num, len_train_val_set + i * max_loaded_imgs_num )\n",
    "    # elvaluation of test data\n",
    "\n",
    "# If there are images left in the last section, execute last test cycle.\n",
    "#if(len_last_section_test != 0):\n",
    "#    (X_test, Y_test) = preprocess_test_data(transformed_dataset_path, len_last_section_test, len_train_val_set + (num_cycles_test - 1) * max_loaded_imgs_num )\n",
    "    # evaluation of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2TE2qi9CTp0h",
    "outputId": "1c03b5f4-17f7-476e-8b29-e98e4fcd753a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating average and std value on train data. 2018-11-06 15:54:44.866816\n",
      "2045/95752\n",
      "10011/95752\n",
      "17992/95752\n",
      "26122/95752\n",
      "34242/95752\n",
      "41683/95752\n",
      "49471/95752\n",
      "57452/95752\n",
      "65473/95752\n",
      "73445/95752\n",
      "81489/95752\n",
      "89525/95752\n",
      "Calculated average and std value, 2018-11-06 16:06:46.433307\n"
     ]
    }
   ],
   "source": [
    "datetime.datetime.now()\n",
    "print('Start calculating average and std value on train data. '+str(datetime.datetime.now()))\n",
    "std,ave = dataset_std(transformed_dataset_path,128,valid_split,test_split)\n",
    "print('Calculated average and std value, '+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.16514176432521 28.18332749171332\n"
     ]
    }
   ],
   "source": [
    "print(ave, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "Z0XF7JXze66O",
    "outputId": "e96ca71e-4f4b-4633-d448-790a30e08635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start transforming images to csv files. 2018-11-06 16:07:53.980275\n",
      "53/95752\n",
      "618/95752\n",
      "1188/95752\n",
      "1756/95752\n",
      "2319/95752\n",
      "2878/95752\n",
      "3438/95752\n",
      "3996/95752\n",
      "4542/95752\n",
      "5085/95752\n",
      "5627/95752\n",
      "6162/95752\n",
      "6719/95752\n",
      "7279/95752\n",
      "7805/95752\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-9167afd234fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Start transforming images to csv files. '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcsv_dataset_path\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'E:/Deep_Learning_HW/csv_dataset/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdataset_normalized_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_dataset_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcsv_dataset_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mave\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Transformed images to csv files. '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-b8790c41b276>\u001b[0m in \u001b[0;36mdataset_normalized_csv\u001b[1;34m(initial_path, target_path, array_average, array_std)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mimage_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m#Saving to a csv files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1379\u001b[0m                                     \u001b[1;34m\"format specifier ('%s')\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m                                     % (str(X.dtype), format))\n\u001b[1;32m-> 1381\u001b[1;33m                 \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print('Start transforming images to csv files. '+str(datetime.datetime.now()))\n",
    "csv_dataset_path ='E:/Deep_Learning_HW/csv_dataset/'\n",
    "dataset_normalized_csv(transformed_dataset_path,csv_dataset_path,ave,std)\n",
    "print('Transformed images to csv files. '+str(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jdEjTfq8rlAa"
   },
   "outputs": [],
   "source": [
    "#Class TrainingHistory\n",
    "class TrainingHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses=[]\n",
    "        self.valid_losses =[]\n",
    "        self.accs = []\n",
    "        self.valid_accs = []\n",
    "        self.epoch=0\n",
    "    \n",
    "    def on_epoch_end(self, epoch,logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.valid_losses.append(logs.get('val_loss'))\n",
    "        self.accs.append(logs.get('acc'))\n",
    "        self.valid_accs.append(logs.get('val_acc'))\n",
    "        self.epoch += 1\n",
    "#Initializing the history  \n",
    "history = TrainingHistory()\n",
    "\n",
    "#Defining the earlystopping\n",
    "es = EarlyStopping(patience=10, verbose=1)\n",
    "mcp = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZBL8XSxuDRj"
   },
   "outputs": [],
   "source": [
    "model = Sequential();\n",
    "model.add(Conv2D(data_format=\"channels_first\",input_shape=(128, 128,1), filters=32, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=32, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=32, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=64, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=128, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=128, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=128, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(data_format=\"channels_first\",filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='linear', use_bias=False))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(1024, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Dense(2*128*128, activation='linear'))\n",
    "model.add(Activation('sigmoid'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vd-wkdfOuGv3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 128, 128)\n",
      "(88, 128, 128, 2)\n",
      "(12, 128, 128)\n",
      "(12, 128, 128, 2)\n",
      "Train on 88 samples, validate on 12 samples\n",
      "Epoch 1/10\n",
      " - 33s - loss: 209189.8031 - val_loss: 216044.8177\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 216044.81771, saving model to weights.hdf5\n",
      "Epoch 2/10\n",
      " - 32s - loss: 211424.5149 - val_loss: 216044.8177\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 216044.81771\n",
      "Epoch 3/10\n",
      " - 32s - loss: 211424.5149 - val_loss: 216044.8177\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 216044.81771\n",
      "Epoch 4/10\n",
      " - 32s - loss: 211424.5149 - val_loss: 216044.8177\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 216044.81771\n",
      "Epoch 5/10\n",
      " - 33s - loss: 211424.5149 - val_loss: 216044.8177\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 216044.81771\n",
      "Epoch 6/10\n",
      " - 33s - loss: 211424.5149 - val_loss: 216044.8177\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 216044.81771\n",
      "Epoch 7/10\n",
      " - 33s - loss: 211424.5149 - val_loss: 216044.8177\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 216044.81771\n",
      "Epoch 8/10\n",
      " - 32s - loss: 211424.5149 - val_loss: 216044.8177\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 216044.81771\n",
      "Epoch 9/10\n",
      " - 35s - loss: 211424.5149 - val_loss: 216044.8177\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 216044.81771\n",
      "Epoch 10/10\n",
      " - 34s - loss: 211424.5149 - val_loss: 216044.8177\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 216044.81771\n"
     ]
    }
   ],
   "source": [
    "sgd=SGD(lr=1, momentum=0.09, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "(X_train,Y_train,X_valid,Y_valid) = preprocess_train_valid_data('E:/Deep_Learning_HW/csv_dataset/', train_split, valid_split, 100, 0)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n",
    "\n",
    "hst = model.fit(X_train.reshape((-1,128,128,1)), Y_train.reshape((-1,2*128*128)),\\\n",
    "         batch_size=1,\n",
    "         epochs=10,\n",
    "         verbose=2,\n",
    "         validation_data=(X_valid.reshape((-1,128,128,1)),Y_valid.reshape((-1,2*128*128))),\n",
    "         callbacks=[mcp, es, history],\n",
    "         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ngak2lXuKe4"
   },
   "outputs": [],
   "source": [
    "preds=model.predict(inputArrayT).reshape((2,128,128,2))*255\n",
    "visual=np.empty((2,128,128,3))\n",
    "visual[:,:,:,0]=npImageArrayT[:,:,:,0]\n",
    "visual[:,:,:,1::]=preds-127\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(skcolor.lab2rgb(visual[0]))\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(imageArrayt[0])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h31DKQZbuS10"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.title(\"Hiba mértéke a tanítás során\")\n",
    "plt.plot(np.arange(history.epoch), history.losses, color='g',  \n",
    "         label=\"Hiba a tanító adatokon\")\n",
    "plt.plot(np.arange(history.epoch), history.valid_losses, color='r',\n",
    "         label=\"Hiba a validációs adatokon\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Epochok száma\")\n",
    "plt.ylabel(\"Hiba\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ColorNet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
